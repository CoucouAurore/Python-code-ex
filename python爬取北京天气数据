import requests
import pandas as pd

url = 'https://tianqi.2345.com/Pc/GetHistory'

headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36"
}

def craw_table(year, month):
    params = {
        "areaInfo[areaId]": 54511,
        "areaInfo[areaType]": 2,
        "date[year]": year,
        "date[month]": month
    }

    resp = requests.get(url, headers=headers, params=params)
    data = resp.json()["data"]
    df = pd.read_html(data)[0]
    return df

df_list = []
for year in range(2011, 2022):
    for month in range(1, 13):
        print("爬取：", year, month)
        df = craw_table(year, month)
        df_list.append(df)

final_df = pd.concat(df_list)
final_df.to_excel("北京10年天气数据.xlsx", index=False)
