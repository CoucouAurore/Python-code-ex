Here's a quick guide to writing a simple web scraping code in Python using the BeautifulSoup library:

1.Install Required Libraries:
Ensure you have the necessary libraries installed. You can install them using pip:
$$
pip install requests beautifulsoup4

2.Import Libraries:
Import the required libraries at the beginning of your Python script:
$$
import requests
from bs4 import BeautifulSoup

3.Send an HTTP Request:
Use the requests library to send an HTTP GET request to the URL of the web page you want to scrape:
$$
url = 'https://example.com'
response = requests.get(url)

4.Check Response Status:
Check if the request was successful (status code 200):
$$
if response.status_code == 200:
    # Continue with parsing the HTML content
else:
    print('Failed to retrieve the web page.')

5.Parse HTML Content:
Use BeautifulSoup to parse the HTML content of the page:
$$
soup = BeautifulSoup(response.text, 'html.parser')

6.Locate Elements:
Use BeautifulSoup's methods like find, find_all, or CSS selectors to locate the HTML elements you want to scrape. 
For example:
$$
# Find all <a> elements with a specific class
links = soup.find_all('a', class_='my-link-class')

7.Extract Data:
Loop through the elements you found and extract the data you need:
$$
for link in links:
    # Extract text and attributes
    text = link.text
    href = link['href']
    # Process or store the data as needed

8.Close the HTTP Session:
Close the HTTP session when you're done:
$$
response.close()

9.Ethical Considerations:
Be a responsible web scraper and respect the website's terms of service and robots.txt file. 
Don't overload the server with too many requests.
10.Error Handling:
Implement error handling and consider using try-except blocks to handle exceptions that may occur during scraping.
11.Data Storage:
Depending on your use case, you might want to store the scraped data in a file or a database.
12.Testing and Debugging:
Test your scraper on a small scale first and use print statements for debugging.
